{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single Cell for Non-Interactive Sequential Visualization (First 10 Steps)\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "import sys\n",
    "\n",
    "# --- Matplotlib Magic Command (For static plots in output) ---\n",
    "%matplotlib inline\n",
    "\n",
    "# --- << SET THIS GLOBAL VARIABLE >> ---\n",
    "# Change this path to the specific .pth file you want to visualize\n",
    "EPISODE_FILE_PATH = \"./dataset/<chess>_epi1.pth\"\n",
    "# Example: EPISODE_FILE_PATH = \"./dataset/<chess>_pseudo_illegal_epi1.pth\"\n",
    "\n",
    "# --- Configuration (Should match dataset generation) ---\n",
    "FRAME_SIZE = (512, 512, 3)  # (Height, Width, Channels)\n",
    "TORCH_DATA_TYPE = torch.float32\n",
    "GAME_NAME_TOKEN = \"<chess>\" # Or whatever token you used for the first action\n",
    "FINAL_ACTION_TOKEN = \"<exit>\"\n",
    "STEPS_TO_SHOW = 10 # Limit visualization to the first N steps\n",
    "\n",
    "# --- Helper Function ---\n",
    "def tensor_to_pil(tensor):\n",
    "    \"\"\"Converts a (H, W, C) tensor scaled [-1, 1] back to a PIL Image (RGB).\"\"\"\n",
    "    if not isinstance(tensor, torch.Tensor):\n",
    "        print(f\"Warning: Expected a Tensor, got {type(tensor)}. Attempting conversion.\")\n",
    "        try:\n",
    "            tensor = torch.tensor(tensor, dtype=TORCH_DATA_TYPE)\n",
    "            if tensor.shape != FRAME_SIZE:\n",
    "                 raise ValueError(f\"Converted tensor shape {tensor.shape} doesn't match FRAME_SIZE {FRAME_SIZE}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error converting input to tensor: {e}\")\n",
    "            return Image.new('RGB', (FRAME_SIZE[1], FRAME_SIZE[0]), (255, 0, 0)) # Red error image\n",
    "\n",
    "    if tensor.is_cuda:\n",
    "        tensor = tensor.cpu()\n",
    "    tensor = tensor.to(torch.float32)\n",
    "    if tensor.shape != FRAME_SIZE:\n",
    "         print(f\"Error: Input tensor shape {tensor.shape} does not match expected FRAME_SIZE {FRAME_SIZE}\")\n",
    "         return Image.new('RGB', (FRAME_SIZE[1], FRAME_SIZE[0]), (255, 0, 255)) # Magenta error image\n",
    "\n",
    "    tensor = tensor.permute(2, 0, 1) # HWC to CHW\n",
    "    tensor = (tensor + 1.0) / 2.0    # [-1, 1] to [0, 1]\n",
    "    tensor = torch.clamp(tensor, 0, 1)\n",
    "    try:\n",
    "        pil_image = transforms.ToPILImage()(tensor)\n",
    "    except Exception as e:\n",
    "        print(f\"Error during transforms.ToPILImage(): {e}\")\n",
    "        return Image.new('RGB', (FRAME_SIZE[1], FRAME_SIZE[0]), (255, 255, 0)) # Yellow error image\n",
    "    return pil_image\n",
    "\n",
    "# --- Main Execution Logic ---\n",
    "\n",
    "print(\"--- Starting Visualization ---\")\n",
    "\n",
    "# --- Basic File Check ---\n",
    "valid_file = False\n",
    "if not isinstance(EPISODE_FILE_PATH, str) or not EPISODE_FILE_PATH:\n",
    "    print(\"Error: EPISODE_FILE_PATH is not set correctly.\")\n",
    "elif not os.path.isfile(EPISODE_FILE_PATH):\n",
    "    print(f\"Error: File not found at '{EPISODE_FILE_PATH}'\")\n",
    "elif not EPISODE_FILE_PATH.endswith(\".pth\"):\n",
    "     print(f\"Warning: File '{os.path.basename(EPISODE_FILE_PATH)}' does not end with .pth.\")\n",
    "     valid_file = True # Allow processing anyway\n",
    "else:\n",
    "    valid_file = True\n",
    "\n",
    "if valid_file:\n",
    "    # --- Load Data ---\n",
    "    print(f\"Loading episode data from: {EPISODE_FILE_PATH}\")\n",
    "    try:\n",
    "        episode_data = torch.load(EPISODE_FILE_PATH, map_location=torch.device('cpu'))\n",
    "\n",
    "        if not isinstance(episode_data, dict):\n",
    "             print(f\"Error: Loaded file is not a dictionary. Found type: {type(episode_data)}\")\n",
    "        else:\n",
    "            # --- Data Validation ---\n",
    "            required_keys = ['previous_frames', 'actions', 'target_frames']\n",
    "            if not all(key in episode_data for key in required_keys):\n",
    "                print(\"Error: Loaded dictionary is missing required keys.\")\n",
    "            else:\n",
    "                prev_frames = episode_data['previous_frames']\n",
    "                actions = episode_data['actions']\n",
    "                target_frames = episode_data['target_frames']\n",
    "                num_transitions = len(actions)\n",
    "                print(f\"  Total transitions in file: {num_transitions}\")\n",
    "\n",
    "                # Add shape/type validation if desired (copied from previous versions)\n",
    "                if not isinstance(prev_frames, torch.Tensor) or not isinstance(target_frames, torch.Tensor) or \\\n",
    "                   prev_frames.shape[0] != num_transitions or target_frames.shape[0] != num_transitions or \\\n",
    "                   prev_frames.shape[1:] != FRAME_SIZE or target_frames.shape[1:] != FRAME_SIZE:\n",
    "                    print(\"Error: Data validation failed (type, count, or shape mismatch).\")\n",
    "                else:\n",
    "                    # --- Sequential Plotting Loop ---\n",
    "                    num_to_show = min(STEPS_TO_SHOW, num_transitions)\n",
    "                    print(f\"Displaying the first {num_to_show} transitions sequentially:\")\n",
    "\n",
    "                    for i in range(num_to_show):\n",
    "                        print(f\"\\n--- Transition {i+1}/{num_to_show} ---\")\n",
    "                        prev_frame_tensor = prev_frames[i]\n",
    "                        action = actions[i]\n",
    "                        target_frame_tensor = target_frames[i]\n",
    "\n",
    "                        is_illegal_attempt = False\n",
    "                        if action != GAME_NAME_TOKEN and action != FINAL_ACTION_TOKEN:\n",
    "                             if torch.allclose(prev_frame_tensor, target_frame_tensor, atol=1e-6):\n",
    "                                  is_illegal_attempt = True\n",
    "\n",
    "                        prev_img = tensor_to_pil(prev_frame_tensor)\n",
    "                        target_img = tensor_to_pil(target_frame_tensor)\n",
    "\n",
    "                        # *** Create a NEW figure for each step ***\n",
    "                        fig, ax = plt.subplots(1, 2, figsize=(9, 4.5)) # Smaller size for inline\n",
    "\n",
    "                        ax[0].imshow(prev_img)\n",
    "                        ax[0].set_title(f\"Prev Frame ({i+1})\")\n",
    "                        ax[0].axis(\"off\")\n",
    "\n",
    "                        ax[1].imshow(target_img)\n",
    "                        title_suffix = \" (Illegal Attempt!)\" if is_illegal_attempt else \"\"\n",
    "                        ax[1].set_title(f\"Action: '{action}'{title_suffix}\")\n",
    "                        ax[1].axis(\"off\")\n",
    "\n",
    "                        # fig.suptitle(f\"Transition {i+1}/{num_to_show}\", fontsize=10) # Optional overall title\n",
    "                        fig.tight_layout()\n",
    "\n",
    "                        # *** Show the current figure inline ***\n",
    "                        plt.show(fig)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn error occurred while loading or visualizing the file:\")\n",
    "        print(e)\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "print(\"\\n--- Visualization cell finished ---\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
